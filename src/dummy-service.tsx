export const ai_chat = {
    "reply": "Something went wrong, please try again",
    "model": "meta-llama/llama-3-8b-instruct",
    "usage": {
        "prompt_tokens": 41,
        "completion_tokens": 55,
        "total_tokens": 96,
        "prompt_tokens_details": null,
        "completion_tokens_details": null
    }
}